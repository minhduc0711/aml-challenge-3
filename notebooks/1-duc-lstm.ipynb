{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4fa434-0046-4d74-bc04-3f46a58dd17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b152a43-06cc-4f77-b9db-df5bc252663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc3a014-da59-4e15-8102-d6f8748adfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained Glove\n",
      "[==================================================] 100.0% 758.5/758.5MB downloaded\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from src.features.vectorizer import get_glove_vectorizer\n",
    "\n",
    "glove_vectorizer = get_glove_vectorizer(maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5b39154-7aa0-4238-af9e-4f3c5ae1ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_module import TextDataModule\n",
    "from src.features.preprocess import preprocess\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "dm = TextDataModule(vectorizer_fn=glove_vectorizer,\n",
    "                    preprocess_fn=preprocess,\n",
    "                    tokenize_fn=word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34a85604-8a7e-4859-b34a-214423dff7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type     | Params\n",
      "--------------------------------------\n",
      "0 | lstm     | LSTM     | 35.5 K\n",
      "1 | fc       | Linear   | 123   \n",
      "2 | accuracy | Accuracy | 0     \n",
      "--------------------------------------\n",
      "35.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "35.6 K    Total params\n",
      "0.143     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873635faf0324723b1c43e9a6ddc5c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 398, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/notebooks/aml-challenge-3/src/data/dataset.py\", line 43, in __getitem__\n    x = self.vectorizer_fn(text)\n  File \"/notebooks/aml-challenge-3/src/features/vectorizer.py\", line 29, in transform\n    x = np.vstack(x)\n  File \"<__array_function__ internals>\", line 180, in vstack\n  File \"/opt/conda/lib/python3.8/site-packages/numpy/core/shape_base.py\", line 282, in vstack\n    return _nx.concatenate(arrs, 0)\n  File \"<__array_function__ internals>\", line 180, in concatenate\nValueError: need at least one array to concatenate\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m logger \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mloggers\u001b[38;5;241m.\u001b[39mTensorBoardLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlightning_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm-glove\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(callbacks\u001b[38;5;241m=\u001b[39m[early_stopping], accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger\u001b[38;5;241m=\u001b[39mlogger)\n\u001b[0;32m---> 57\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    807\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    809\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    810\u001b[0m )\n\u001b[0;32m--> 811\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1236\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[0;32m-> 1236\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1238\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1323\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1353\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1353\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:269\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(\n\u001b[1;32m    266\u001b[0m     dataloader, batch_to_device\u001b[38;5;241m=\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_strategy_hook, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_to_device\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataloader_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    267\u001b[0m )\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:171\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001b[1;32m    170\u001b[0m     batch_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 171\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     batch_idx, batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_fetcher)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py:184\u001b[0m, in \u001b[0;36mAbstractDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetching_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py:259\u001b[0m, in \u001b[0;36mDataFetcher.fetching_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_next_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# consume the batch we just fetched\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py:273\u001b[0m, in \u001b[0;36mDataFetcher._fetch_next_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetch_next_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator: Iterator) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m     start_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_fetch_start()\n\u001b[0;32m--> 273\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetched \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefetch_batches \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_len:\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;66;03m# when we don't prefetch but the dataloader is sized, we use the length for `done`\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py:553\u001b[0m, in \u001b[0;36mCombinedLoaderIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;124;03m\"\"\"Fetches the next batch from multiple data loaders.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m        a collections of batch data\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_next_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader_iters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py:565\u001b[0m, in \u001b[0;36mCombinedLoaderIterator.request_next_batch\u001b[0;34m(loader_iters)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest_next_batch\u001b[39m(loader_iters: Union[Iterator, Sequence, Mapping]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the batch of data from multiple iterators.\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m        Any: a collections of batch data\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py:99\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Breaking condition\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype) \u001b[38;5;129;01mand\u001b[39;00m (wrong_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, wrong_dtype)):\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m elem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(data)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Recursively apply to collection items\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1212\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1238\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1238\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_utils.py:438\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 398, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/notebooks/aml-challenge-3/src/data/dataset.py\", line 43, in __getitem__\n    x = self.vectorizer_fn(text)\n  File \"/notebooks/aml-challenge-3/src/features/vectorizer.py\", line 29, in transform\n    x = np.vstack(x)\n  File \"<__array_function__ internals>\", line 180, in vstack\n  File \"/opt/conda/lib/python3.8/site-packages/numpy/core/shape_base.py\", line 282, in vstack\n    return _nx.concatenate(arrs, 0)\n  File \"<__array_function__ internals>\", line 180, in concatenate\nValueError: need at least one array to concatenate\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "class LSTMClassifier(pl.LightningModule):\n",
    "    def __init__(self, embedding_dim, h_dim, n_classes,\n",
    "                 bidirectional=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        self.lstm = nn.LSTM(embedding_dim, h_dim, \n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        D = 2 if bidirectional else 1\n",
    "        self.fc = nn.Linear(h_dim * D, n_classes)\n",
    "        \n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        # Shape (D, batch, h_dim) -> (batch, D * h_dim)\n",
    "        x = hn.permute(1, 0, 2).reshape(N, -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch[\"feat\"].float(), batch[\"labels\"]\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        self.log(\"train/acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch[\"feat\"].float(), batch[\"labels\"]\n",
    "        y_hat = self(x)\n",
    "        val_loss = F.cross_entropy(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        self.log(\"val/loss\", val_loss)\n",
    "        self.log(\"val/acc\", acc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "# x = torch.randn(128, 64, 200)\n",
    "# print(x.dtype)\n",
    "model = LSTMClassifier(200, 20, 3, bidirectional=True)\n",
    "\n",
    "early_stopping = pl.callbacks.EarlyStopping('val/acc', patience=10, mode='max')\n",
    "logger = pl.loggers.TensorBoardLogger(\"lightning_logs\", name=\"lstm-glove\")\n",
    "trainer = pl.Trainer(callbacks=[early_stopping], accelerator=\"gpu\", logger=logger)\n",
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32b3c6fd-1fdf-448b-8cd2-cd0093657771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "lens = []\n",
    "for x, _ in tqdm(dm.subsets[\"train_full\"]):\n",
    "    lens.append(len(x))\n",
    "\n",
    "plt.hist(lens,range=(0, 50))\n",
    "np.quantile(lens, 0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
